{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up and Running with Python3\n",
    "# Data Analysis\n",
    "\n",
    "In this notebook we will see:\n",
    "- _Pandas_ for expanding data slicing capabilities\n",
    "- _uproot_ for opening a ROOT file in pure python and numpy\n",
    "- _Matplotlib_ for plotting (static)\n",
    "- _Plotly_ for plotting (interactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is built on top of NumPy and it could be loosely described as NumPy with labels. That is, it is a package that deals with data in tabular form but which attaches more general labels and not just numerical indices to the rows and columns. \n",
    "\n",
    "Here, when we say, \"tables,\" we include also one dimensional vectors, three dimensional data cubes, and so on. \n",
    "\n",
    "Pandas significantly enhances NumPy. In addition to adding data labels and descriptive indices, it is also more robust in handling common data formats and missing data. It also adds relational-database operations, such as joins. \n",
    "\n",
    " Pandas DataFrames extend NumPy two-dimensional arrays by giving labels to the columns and if you provide an explicit index, also to the rows.\n",
    " \n",
    "<img src=\"data/logos/1920px-Pandas_logo.svg.png\" style=\"width: 250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row (or record) and a column.\n",
    "\n",
    "For example, we can construct the record for a neutrino interaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Particle': [14, 13, 2212], \n",
    "                   'Energy': [0.589766 , 0.489765, 0.959907], \n",
    "                   'State' : ['Initial', 'Final', 'Final']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask for the `shape` of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the lenght:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we can access the property of an object by accessing it as an attribute. A book object, for example, might have a title property, which we can access by calling book.title. Columns in a pandas DataFrame work in much the same way.\n",
    "\n",
    "In this example, you can use df.Particle, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCERCISE: Try to access data from the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a Python dictionary, we can access its values using the indexing (`[]`) operator. We can do the same with columns in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCERCISE: Try to access data from the DataFrame as if it were a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has some nice functions that can be applied to the dataframe, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean energy:', df['Energy'].mean())\n",
    "print('counts:', df['Energy'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more things to show about Pandas, and we only cover a few of them. You can find many more information online, for example in this [Kaggle tutorial](https://www.kaggle.com/learn/pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uproot\n",
    "\n",
    "[uproot](https://uproot.readthedocs.io/en/latest/) allows you to do ROOT I/O in pure Python and Numpy.\n",
    "\n",
    "From the documentation page:\n",
    "\n",
    "    uproot is a reader and a writer of the ROOT file format using only Python and Numpy. Unlike the standard C++ ROOT implementation, uproot is only an I/O library, primarily intended to stream data into machine learning libraries in Python. Unlike PyROOT and root_numpy, uproot does not depend on C++ ROOT. Instead, it uses Numpy to cast blocks of data from the ROOT file as Numpy arrays.\n",
    "    \n",
    "<img src=\"data/logos/uproot-logo-300px.png\" style=\"width: 250px;\">\n",
    "   \n",
    "Let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `uproot.open(filename)` to open a new file.\n",
    "\n",
    "- `.keys()` allows you to browse what is inside the file\n",
    "\n",
    "- If you want to read TTree branch called, for example, 'particles', you do f\n",
    "\n",
    "For example\n",
    "```\n",
    "f = uproot.open(filename.root)\n",
    "\n",
    "# Browse what is inside the file\n",
    "print('Keys:', f.keys())\n",
    "\n",
    "# If you want to read a TTree called, for example, 'mytree', you do:\n",
    "t = f['mytree']\n",
    "\n",
    "# You can now print the name, title and number of entries in the tree\n",
    "print('Tree name:', t.name)\n",
    "print('Tree title:', t.title)\n",
    "print('Number of entries:', t.numentries)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening a CAF File with uproot\n",
    "\n",
    "As an example on how we can use `uproot`, we are going to open an expore one of the CAFAna files that Fernanda showed in the tutorial yesterday!\n",
    "\n",
    "The file is in the `data` directory, and is called `larout.caf.root`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Explore what is in the CAF file\n",
    "f = uproot.open('data/larout.caf.root')\n",
    "\n",
    "t = f['recTree']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.keys()` again to list what are the branches in the Tree.\n",
    "We can also use `.show()` for a more in-depth look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start loading all branches that start with `hdr`. This is the \"header\" and contains the metadata of the events.\n",
    "\n",
    "We are also now converting the Tree to a `pandas` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdr = t.pandas.df('hdr*')\n",
    "df_hdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get all the slice information. They are in branches that start with `slc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slc = f['recTree'].pandas.df('slc*', flatten=False)\n",
    "df_slc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note about DataFrames:\n",
    "\n",
    "- DataFrames are great but some care is required when designing their structure.\n",
    "\n",
    "- DataFrames work great with a hierarchical structure. For example, if you store all the events and all the tracks per event this is fine, but problems appear if you start storing both tracks and showers in the same dataframe for example, as one event has different numbers of tracks and shower. Some of the problems that arise are solvable, but require some efforts. \n",
    "\n",
    "- Always make sure you design your DataFrame to be as flat as possible, and hirerchical.\n",
    "\n",
    "Example, try to import both the `slc` and the `reco` branches in the same DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f['recTree'].pandas.df(['slc*', 'reco*'] , flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... yes... it fails "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "\n",
    "Matplotlib is a plotting library for Python and NumPy. We will see more about matplotlib later, but here you can immediately see how easy it is to use from a pandas dataframe.\n",
    "\n",
    "<img src=\"data/logos/matplotlib.png\" style=\"width: 250px;\">\n",
    "\n",
    "From a pandas dataframe, we can immediately plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slc['slc.vertex.x'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slc.plot.scatter(x='slc.vertex.z', y='slc.vertex.y', color='DarkBlue', label='Vertices');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "\n",
    "[seaborn](https://seaborn.pydata.org) is a Python data visualization library based on matplotlib.\n",
    "\n",
    "It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "Let's see seaborn in action. First, let's import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let do the same scatte plot, but with seaborn's `jointpolt` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('slc.vertex.z','slc.vertex.y', df_slc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With seaborn, we can also plot more variables simultaneously, and look at their correlations.\n",
    "\n",
    "Here, let's look at the correlation between:\n",
    "- the number of points in a track\n",
    "- the track lenght\n",
    "- the $\\cos\\theta$ of the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['reco.trk.npts', 'reco.trk.len', 'reco.trk.costh']\n",
    "\n",
    "df_reco = f['recTree'].pandas.df(variables, flatten=True)\n",
    "\n",
    "sns.pairplot(df_reco, vars=variables, plot_kws={'s':6, 'alpha':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Higgs Potential with Matplotlib\n",
    "\n",
    "Before we saw matplotlib in action calling it from a dataframe. Here we make a plot calling matplotlib ourself.\n",
    "\n",
    "Let's make a plot of the Higgs potential\n",
    "$V(\\phi) = \\mu^2\\phi^\\dagger\\phi + \\lambda(\\phi^\\dagger\\phi)^2$\n",
    "using Matplotlib. \n",
    "\n",
    "In this example we use pure NumPy and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's use a mu = -10 \n",
    "# and a lambda of 1.4\n",
    "mu = -10 # Higgs potential\n",
    "#mu = 8  # Unique minimum\n",
    "l = 1.4 \n",
    "\n",
    "# Start in radial coordinates, \n",
    "# we generate a meshgrid with \n",
    "# r and theta values:\n",
    "r = np.linspace(0, 3, 400)\n",
    "theta = np.linspace(-0.9 * np.pi, 0.7 * np.pi, 200)\n",
    "r, theta = np.meshgrid(r, theta)\n",
    "\n",
    "# Then we go from radial\n",
    "# to Cartesian coordinates\n",
    "X = r * np.sin(theta)\n",
    "Y = r * np.cos(theta)\n",
    "\n",
    "# And we calculate the value of\n",
    "# the potential:\n",
    "V = mu*r**2 + l*r**4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(X, Y, V, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none', antialiased=False);\n",
    "\n",
    "ax.set_xlabel('Re $\\phi$', fontsize=18)\n",
    "ax.set_ylabel('Im $\\phi$', fontsize=18)\n",
    "ax.set_zlabel('V($\\phi)$', fontsize=18)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Pandas, Event Selection, and Plotting\n",
    "\n",
    "In this example we take a ROOT file obtained from a LArSoft analyzer, which contains some truth basic variables. \n",
    "\n",
    "We use uproot to open the file and convert the `TTree` to a Pandas `DataFrame`.\n",
    "\n",
    "We then apply a simple event selection using the Pandas `DataFrame::query()` function.\n",
    "\n",
    "Finally, we make a plot of neutrino interactions as a function of neutrino energy.\n",
    "\n",
    "Let's start with opening the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uproot.open('data/sbnd_extracted_genie.root')\n",
    "df = f['extractor/tree'].pandas.df()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Select only event with neutrinos in the TPC x in [-200, 200], y in [-200, 200] and z in [0, 500]\n",
    "# Also select only events with muon neutrinos interacting CC,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCERCISE: Make an histogram with the neutrino energy using \"ax.hist\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10,6))\n",
    "\n",
    "#\n",
    "# ...\n",
    "#\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we see how to plot the same histogram using `step`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the bins using \"np.linspace\":\n",
    "x_min = 0\n",
    "x_max = 6\n",
    "n_bins = 100\n",
    "bins = np.linspace(x_min, x_max, n_bins+1)\n",
    "\n",
    "# Get the data in numpy array:\n",
    "data = df['nu_e'].values\n",
    "\n",
    "# We use \"np.histogram\" to build the histogram:\n",
    "h, _ = np.histogram(data, bins=bins)\n",
    "h = np.append(h, h[-1])\n",
    "\n",
    "# Finally, plot it!\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10,6))\n",
    "\n",
    "ax.step(bins, h)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly\n",
    "\n",
    "Plotly provides online graphing, analytics, and statistics tools for many languages like Python, R, MATLAB, Perl, Julia, Arduino, and REST.\n",
    "\n",
    "It allows to make nice interactive plots, like the ones we are going to do below.\n",
    "\n",
    "Also, it has a nice a extention to make plots that remain interactive on the browser, called `Dash`.\n",
    "\n",
    "<img src=\"data/logos/plotly.png\" style=\"width: 250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df, x=\"nu_e\", nbins=100, histnorm='probability density')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCERCISE: Try to add option  marginal=\"violin\", or \"rug\", \"box\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "pmt_geom = yaml.load(open('data/sbnd_pmts_tpc0.yaml').read(), Loader=yaml.Loader)['PMTGeom']\n",
    "\n",
    "pmts = {}\n",
    "for key, value in pmt_geom.items():\n",
    "    pmts[key] = value\n",
    "    \n",
    "pmts_y = []\n",
    "pmts_z = []\n",
    "for p in pmts.values():\n",
    "    pmts_y.append(p[1])\n",
    "    pmts_z.append(p[2])\n",
    "    \n",
    "pmt_mask = np.zeros(492, dtype=bool)\n",
    "for i in range(0, 492):\n",
    "    if i in pmt_geom.keys():\n",
    "        pmt_mask[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = uproot.open('data/flashfinder_tree.root')\n",
    "f.keys()\n",
    "df = f['flashana/FlashTree'].pandas.df('flash*', flatten=False)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 0\n",
    "flash_pe_v = df['flash_pe_v'][event]\n",
    "\n",
    "flash_pe_v = flash_pe_v[pmt_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=pmts_z,\n",
    "                                y=pmts_y,\n",
    "                                mode='markers',\n",
    "                                marker=dict(size=[30]*len(pmts_z),\n",
    "                                            color=flash_pe_v),\n",
    "                                text=flash_pe_v\n",
    "                               )\n",
    "               )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [vis_icarus](http://web.stanford.edu/~kterao/Event144.html) by Kazu for a beautiful 3D rendering! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "Now we are going to look into a fitting example using Python.\n",
    "\n",
    "For this example, we will take a ROOT file created by the SBND analyzer called `HitDumper`, which is the analyzer we are using for the SBND commissioning studies.\n",
    "\n",
    "Among other information, this file contains all the reconstructed hits in the event.\n",
    "\n",
    "The file is generated from particle gun, by producing muon that cross the detector longitudinally at different  `x` positions.\n",
    "\n",
    "The idea of this example is:\n",
    "\n",
    "- Get all the hits from TPC 0 and on the collection plane\n",
    "- Group the hits in different `x` regions, based on the hit time\n",
    "- Calculate the median hit integral value in every `x` region\n",
    "- Fit these median values as a function of `x` (or drift time `t`) using $f(t) = e^{-t/\\tau}$\n",
    "- Extract the electron lifetime $\\tau$\n",
    "\n",
    "We are going to \"slice\" the SBND TPC in 10 regions of `x`:\n",
    "<img src=\"data/sbnd_sliced.png\" style=\"width: 300px;\">\n",
    "These regions can be identified by the CRT. \n",
    "\n",
    "Let's start by opening the ROOT file `hitdumper_tree.root`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(\"data/hitdumper_tree.root\")\n",
    "df_original = file['hitdumper/hitdumpertree'].pandas.df(\"hit_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in this dataframe with have both `entry` and `subentry`. This is what is called a _multiindex_ dataframe. Here, in every event we have multiple hits, indexed by `subentry`.\n",
    "\n",
    "Multiindex dataframe are powerful, and more details can be found in the Pandas [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas `dropna()` to drop all the rows with NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we select hits from TPC 0 and from the collection plane only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXCERICE: Select only hits in hit_tpc == 0 and hit_plane == 2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot all the hit charge vs the hit time.\n",
    "\n",
    "We can use matplotlib `hist2d` to make a 2D histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10, 6))\n",
    "\n",
    "limits = [[0, 2500], [300, 800]]\n",
    "\n",
    "h = ax.hist2d(df_original['hit_peakT'], df_original['hit_charge'], bins=100, range=limits)\n",
    "plt.colorbar(h[3], ax=ax)\n",
    "\n",
    "ax.set_ylabel('Hit Charge [ADC]',fontsize=18)\n",
    "ax.set_xlabel('Drift Time [ticks]',fontsize=18)\n",
    "ax.set_title('Simulated lifetime = 3 ms', loc='right', fontsize=18)\n",
    "ax.tick_params(labelsize=15)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's divide the hits in 10 different regions along the drift direction.\n",
    "\n",
    "For every \"x slice\" we want the median of all the hit's charge.\n",
    "\n",
    "First, let's construct the bin edges along the drift direction and also the center of these bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = np.arange(0, 2750, 250)\n",
    "bin_center = [bin_edges[i]+(bin_edges[i+1]-bin_edges[i])/2 for i in range(len(bin_edges)-1)]\n",
    "print('Bin edges:', bin_edges)\n",
    "print('Bin centers:', bin_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the median of the hit integral in every `x` bin. Where:\n",
    "- `hit_peakT` is the hit peak time\n",
    "- `hit_charge` is the hit integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_median = []\n",
    "\n",
    "for i in range(0, len(bin_edges)-1):\n",
    "    start = bin_edges[i]\n",
    "    end = bin_edges[i+1]\n",
    "    query = f'hit_peakT > {start} and hit_peakT < {end}'\n",
    "    \n",
    "    df_select = df.query(query)\n",
    "    \n",
    "    median = np.median(df_select['hit_charge'].values)\n",
    "    charge_median.append(median)\n",
    "\n",
    "\n",
    "bin_center = np.array(bin_center)\n",
    "charge_median = np.array(charge_median)\n",
    "\n",
    "print('Bin centers:', bin_center)\n",
    "print('Charge medians:', charge_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the points that we just calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10, 6))\n",
    "\n",
    "ax.errorbar(x=bin_center, y=charge_median, marker='o', linestyle='', label='Hit Charge Median')\n",
    "\n",
    "ax.legend(fontsize=18, loc='best')\n",
    "ax.set_xlabel('Drift Time [ticks]',fontsize=18)\n",
    "ax.set_ylabel('Hit Charge [ADC]',fontsize=18)\n",
    "ax.set_title('Simulated lifetime = 3 ms', loc='right', fontsize=18)\n",
    "ax.tick_params(labelsize=15)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to fit these points with an exponential, this is how we do it in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def exp(x, a0, tau):\n",
    "    '''\n",
    "    This defines the exponential function \n",
    "    that depends on a0 and tau\n",
    "    '''\n",
    "    return a0 * np.exp(-x/tau) \n",
    "\n",
    "def fit(func, x, y, seed=(), fit_range=None, **kwargs):\n",
    "    '''\n",
    "    Call this to fit a function func on data x,y\n",
    "    You can pass the initial seeds, and the range \n",
    "    to use for the fit.\n",
    "    '''\n",
    "    if fit_range is not None:\n",
    "        sel = (fit_range[0] <= x) & (x < fit_range[1])\n",
    "        x, y = x[sel], y[sel]\n",
    "        \n",
    "    vals, cov = curve_fit(func, x, y, seed, **kwargs)\n",
    "    \n",
    "    fitf = lambda x: func(x, *vals)\n",
    "    \n",
    "    errors = np.sqrt(np.diag(cov))\n",
    "    \n",
    "    return fitf, vals, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the fit now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 650., 6e3\n",
    "fitf, vals, errs = fit(func=exp, \n",
    "                       x=bin_center, \n",
    "                       y=charge_median, \n",
    "                       seed=seed, \n",
    "                       fit_range=(0, 2500))\n",
    "print('Fit results:', vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's plot the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(12, 8))\n",
    "\n",
    "_sampling = 2 # The 2 us sampling\n",
    "\n",
    "ax.errorbar(x=bin_center, y=charge_median, marker='o', linestyle='', label='Hit Charge Median')\n",
    "\n",
    "x = np.arange(0, 2500)\n",
    "\n",
    "legend = f'Fit: $f(x) = a\\cdot exp(-t/\\\\tau)$ \\n $a$ = {vals[0]:.2} $\\pm$ {errs[0]:.2} \\n $\\\\tau$ = {vals[1]*1e-3/_sampling:.3} $\\pm$ {errs[1]*1e-3/_sampling:.1}'\n",
    "\n",
    "plt.plot(x, fitf(x), 'r-', label=legend)\n",
    "\n",
    "ax.legend(fontsize=18, loc='best')\n",
    "ax.set_xlabel('Drift Time [ticks]',fontsize=18)\n",
    "ax.set_ylabel('Hit Charge [ADC]',fontsize=18)\n",
    "ax.set_title('Simulated lifetime = 3 ms', loc='right', fontsize=18)\n",
    "ax.tick_params(labelsize=15)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Well done! 👏👏👏')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes...you can use Unicode in your string literals! 😁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
